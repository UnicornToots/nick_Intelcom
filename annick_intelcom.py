# -*- coding: utf-8 -*-
"""Annick-Intelcom.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1X6L7NpQqbEwdPAju4ysa5n_PhZYSvU8Q
"""

from google.colab import files
uploaded = files.upload()

import pandas as pd
import numpy as np

df = pd.read_csv('/content/DataScienceChallenge.csv')

df.head(10)

df.info()

print(df['Country'].unique())

print(df['City'].unique())

df['Country'].nunique()

df['City'].nunique()

df.astype({'Daily Time Spent on Site': 'float64'}).dtypes

###Figured dropping the rows seemed better than subsituting the value. The string data seemed useless.

df1 = df.drop(df[df['Daily Time Spent on Site'].str.contains(' ',na=False)].index)

df1.astype({'Daily Time Spent on Site': 'float64'}).dtypes

test = []
countries=[]
id = 1
for i in df1['Country']:
    if i not in test:
        countries.append({
            i:id
        })
        test.append(i)
    id+=1

countries

##I begin to code the string columns here. Lots of repetition.

df1["Country"] = df1["Country"].astype('category')
df1.dtypes

df1["Country.Code"] = df1["Country"].cat.codes
df1.head()

df1.loc[df1['Country'] == 'Tunisia']

df1["City"] = df1["City"].astype('category')
df1["City.Code"] = df1["City"].cat.codes
df1.head()

df1.loc[df1['City'] == 'Wrightburgh']

new = df["Ad Topic Line"].str.split(" ", expand = True)
new.head()

for i in range(len(new.columns)):
  df1['Ad word-'+str(i)] = new[i]

df1.head()

df1["Ad word-0"] = df1["Ad word-0"].astype('category')
df1["Ad word-1"] = df1["Ad word-1"].astype('category')
df1["Ad word-2"] = df1["Ad word-2"].astype('category')
df1["Ad word-3"] = df1["Ad word-3"].astype('category')
df1["Ad word-4"] = df1["Ad word-4"].astype('category')
df1["Ad word-5"] = df1["Ad word-5"].astype('category')

df1["Ad word-0"] = df1["Ad word-0"].cat.codes
df1["Ad word-1"] = df1["Ad word-1"].cat.codes
df1["Ad word-2"] = df1["Ad word-2"].cat.codes
df1["Ad word-3"] = df1["Ad word-3"].cat.codes
df1["Ad word-4"] = df1["Ad word-4"].cat.codes
df1["Ad word-5"] = df1["Ad word-5"].cat.codes
df1.head()

df_no_na = df1.dropna()

df_no_na=df_no_na.drop(columns=['Ad Topic Line', 'City', 'Country'])

df_no_na['Timestamp'] = pd.to_datetime(df_no_na['Timestamp']).astype(int) / 10**9

df_no_na.info()

####I give up here

###Ok ill try.

from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier
from sklearn.model_selection import train_test_split # Import train_test_split function
from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation

feature_cols = ['Daily Time Spent on Site', 'Age', 'Area Income', 'Daily Internet Usage','Male','Timestamp','Country.Code', 'City.Code', 'Ad word-0', 'Ad word-1', 'Ad word-2', 'Ad word-3', 'Ad word-4', 'Ad word-5']
X = df_no_na[feature_cols] # Features
y = df_no_na['Clicked on Ad'] # Target variable

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1) # 80% training and 20% test

# Create Decision Tree classifer object
clf = DecisionTreeClassifier()

# Train Decision Tree Classifer
clf = clf.fit(X_train,y_train)

#Predict the response for test dataset
y_pred = clf.predict(X_test)

print("Accuracy:",metrics.accuracy_score(y_test, y_pred))

!pip install graphviz

!pip install pydotplus

from sklearn.tree import export_graphviz

from six import StringIO
from IPython.display import Image  
import pydotplus

dot_data = StringIO()
export_graphviz(clf, out_file=dot_data,  
                filled=True, rounded=True,
                special_characters=True,feature_names = feature_cols,class_names=['0','1'])
graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  
graph.write_png('diabetes.png')
Image(graph.create_png())

# ======================= Faster Model w/ Less decisions===============================================================
# Create Decision Tree classifer object 
dlf = DecisionTreeClassifier(criterion="entropy", max_depth=3)

# Train Decision Tree Classifer
dlf = dlf.fit(X_train,y_train)

#Predict the response for test dataset
y_pred = dlf.predict(X_test)

# Model Accuracy, how often is the classifier correct?
print("Accuracy:",metrics.accuracy_score(y_test, y_pred))

from six import StringIO
from IPython.display import Image  
from sklearn.tree import export_graphviz
import pydotplus
dot_data = StringIO()
export_graphviz(dlf, out_file=dot_data,  
                filled=True, rounded=True,
                special_characters=True, feature_names = feature_cols,class_names=['0','1'])
graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  
graph.write_png('diabetes.png')
Image(graph.create_png())

df_no_na.head(100)

Trial_Data = np.array([68.95, 35, 61833.90, 256.09, 0, 1.459040e+09, 215, 949, 8, 4, 74, -1, -1, -1])
Trial_Data = Trial_Data.reshape((-1, 14))
Trial_Data = Trial_Data.astype(float)

###['Daily Time Spent on Site', 'Age', 'Area Income', 'Daily Internet Usage','Male','Timestamp','Country.Code', 'City.Code', 'Ad word-0', 'Ad word-1', 'Ad word-2', 'Ad word-3', 'Ad word-4', 'Ad word-5']

clf.predict(Trial_Data)[0]

Trial_Data_Test2 = np.array([66.63, 60, 60333.38, 176.92, 0, 1.452987e+09, 125, 504, 95, 93, 59, -1, -1, -1])
Trial_Data_Test2 = Trial_Data.reshape((-1, 14))
Trial_Data_Test2 = Trial_Data.astype(float)

clf.predict(Trial_Data_Test2)[0]

#####Dimensionality. I haven't tested for dimensionality and fitting.

# Commented out IPython magic to ensure Python compatibility.
import numpy as np 
import pandas as pd 

import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline

import string
import random

from sklearn.pipeline import Pipeline
from sklearn.datasets import make_classification, make_regression
from sklearn.decomposition import PCA
from sklearn.tree import DecisionTreeClassifier, plot_tree, DecisionTreeRegressor
from sklearn.ensemble import RandomForestClassifier

import tubesml as tml

df_test = df_no_na.drop(['Timestamp'],axis=1)

df_test.head()

pca = tml.DfPCA(n_components=0.8)
df_pca = pca.fit_transform(df_no_na.drop('Clicked on Ad', axis=1))
df_pca.head(10)

pca_test = tml.DfPCA(n_components=0.80)
df_pca_test = pca_test.fit_transform(df_test.drop('Clicked on Ad', axis=1))
df_pca_test.head(10)

##I was under the impression that the timestamp was so large a number that it reduced dimensionality in the pca. But instead it creates one principal component anyways. At this point im under the
##impression that the data doesn't need to be reduced.

pca_test = tml.DfPCA(n_components=0.99998)
df_pca_test = pca_test.fit_transform(df_test.drop('Clicked on Ad', axis=1))
df_pca_test.head(10)

##I mean that's hilarious. I'm under the impression there's no reason to compress and run another model. So the above decision tree is my final model, which can be tested below.

Trial_Data = np.array([68.95, 35, 61833.90, 256.09, 0, 1.459040e+09, 215, 949, 8, 4, 74, -1, -1, -1])
Trial_Data = Trial_Data.reshape((-1, 14))
Trial_Data = Trial_Data.astype(float)

clf.predict(Trial_Data)[0]

#Currently can only be tested using coded variables and not the original string.

